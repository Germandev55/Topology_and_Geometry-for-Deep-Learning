{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ID_estimation",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1QmXqnuG7TWn3n9Wt1SvzpLIFjxFpeQfd",
      "authorship_tag": "ABX9TyM2Nixp3v5ZXemH+latoAjx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Germandev55/Topology_and_Geometry-for-Deep-Learning/blob/main/ID_estimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fkP5AxcQUWd"
      },
      "source": [
        "%%capture\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "import IPython\n",
        "from IPython.display import HTML\n",
        "from google.colab import output\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.datasets import cifar10\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import Dense, BatchNormalization, Dropout, Convolution2D, Input,Activation, ZeroPadding2D, MaxPooling2D, Flatten\n",
        "from keras import regularizers\n",
        "\n",
        "import sklearn\n",
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import KernelPCA\n",
        "from sklearn import manifold, datasets\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.manifold import LocallyLinearEmbedding\n",
        "from sklearn.manifold import SpectralEmbedding\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import preprocessing\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "from scipy.spatial import distance_matrix\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "max_abs_scaler = preprocessing.MaxAbsScaler()\n",
        "scaler = StandardScaler()\n",
        "  \n",
        "!pip install ripser\n",
        "\n",
        "import random \n",
        "from ripser import ripser\n",
        "from ripser import Rips\n",
        "\n",
        "import math\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from scipy.optimize import curve_fit\n",
        "import matplotlib.pyplot as plt\n",
        "import mpl_toolkits.mplot3d.axes3d as axes3d"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1OS_iGfQX1T"
      },
      "source": [
        "%%capture\n",
        "!pip install fermat\n",
        "!pip install scikit-dimension\n",
        "from fermat import Fermat\n",
        "import skdim"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZvVFTGlQZDC",
        "outputId": "a5fa8227-eef4-4e14-9d36-448a502b7970"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "# Conver and normalize images [0..255] --> [0..1]\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "# Standarize Images центрирование по каждому каналу \n",
        "mean = np.mean(x_train,axis=(0, 1, 2, 3))\n",
        "std = np.std(x_train,axis=(0, 1, 2, 3)) # стандартное отклонение\n",
        "x_train = (x_train-mean)/(std + 1e-7)\n",
        "x_test = (x_test-mean)/(std + 1e-7)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6rmW0uLRUmC"
      },
      "source": [
        "## Вспомогательные функции"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eG2OHBxQe6r"
      },
      "source": [
        "def features_to_X(x_data, model, index_layer):\n",
        "  input = x_data\n",
        "  layer = model.get_layer(index=index_layer) \n",
        "  #print(layer)\n",
        "  #layer_name = str(layer).split('.')[5].split(' ')[0]\n",
        "  #layer_name = layer\n",
        "  features_layer1 = tf.keras.models.Model(inputs=model.inputs, outputs = layer.output)\n",
        "  output_ = features_layer1(input) \n",
        "  try:\n",
        "    global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "    #global_average_layer = tf.keras.layers.Flatten()\n",
        "    #global_average_layer  = tf.keras.layers.MaxPooling2D(pool_size=(4, 4), strides=None, \n",
        "    #padding=\"valid\", data_format=None)\n",
        "\n",
        "    feature_batch_average = global_average_layer(output_)\n",
        "    X = feature_batch_average\n",
        "    #X = np.reshape(X,(X.shape[0], -1))\n",
        "  except:\n",
        "    X = output_ \n",
        "  #X = features_layer1.predict(input)  \n",
        "  return X, layer\n",
        "\n",
        "def get_Betti(data, eps, maxdim=1):\n",
        "  Betti_layer = []\n",
        "  dgms = ripser(data, maxdim=maxdim, thresh=eps)['dgms']  \n",
        "  inf_in_list = lambda x: 1 if np.isinf(x).any() else 0\n",
        "  Betti_list = [0,0,0]\n",
        "  for e, i in enumerate(dgms):\n",
        "    for x in i: Betti_list[e] += inf_in_list(x)\n",
        "  return sum(Betti_list)\n",
        "\n",
        "def get_Betti_prob(data, eps, alpha, maxdim=2):\n",
        "  dgms = ripser(data, maxdim=maxdim, thresh=eps)['dgms']  \n",
        "  prev_max = 0\n",
        "  list_Hom = []\n",
        "  mean_Hom = []\n",
        "  for Hom in dgms:\n",
        "    B_Hom = 0\n",
        "    for i in Hom:   \n",
        "      if (np.isinf(i).any() == False):\n",
        "        B_Hom += (((i[1]-i[0]))**alpha)*0.5\n",
        "        prev_max = i[1]\n",
        "      else:\n",
        "        #в случае infinity прибавляем последнее время жизни\n",
        "        continue\n",
        "        B_Hom += prev_max \n",
        "\n",
        "    list_Hom.append(B_Hom)\n",
        "    l = len(Hom)\n",
        "    if len(Hom) == 0: l=1\n",
        "    mean_Hom.append(B_Hom/l)\n",
        "\n",
        "  mean_Hom =  [round(x,3) for x in mean_Hom]\n",
        "  return list_Hom, mean_Hom"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUOj-kGdQgYU"
      },
      "source": [
        "def compute_MGST(X, hom_dim) -> float:\n",
        "  MGST, _ = get_Betti_prob(X, eps=np.inf, alpha=1, maxdim=hom_dim)\n",
        "  lfts = round(MGST[hom_dim], 3)\n",
        "  return lfts\n",
        "\n",
        "def MGST_layers(model, examples, layers, hom_dim, fermat_alpha, n_class=1, mode = 'local') -> list:\n",
        "  class_ = n_class\n",
        "  MGST_layers_list = []\n",
        "  for lr in layers:\n",
        "    X_emb, layer_name = features_to_X(x_train[:examples], model, index_layer=lr) \n",
        "    print(layer_name, X_emb.shape)\n",
        "    X_emb = min_max_scaler.fit_transform(X_emb)   \n",
        "      \n",
        "    if mode == 'local':\n",
        "      X_emb_class = []\n",
        "      for e, i in enumerate(y_train[:examples]):\n",
        "        if i == class_: X_emb_class.append(X_emb[e])\n",
        "      Xtest_class = np.array(X_emb_class)\n",
        "    else:\n",
        "      Xtest_class = np.array(X_emb)\n",
        "\n",
        "    MGST_ = compute_MGST_Fermat(Xtest_class, hom_dim, fermat_alpha)\n",
        "    #MGST_ = get_Betti(Xtest_class, eps=eps, maxdim=0)\n",
        "\n",
        "    print(f'{lr}) {MGST_}')\n",
        "    MGST_layers_list.append(MGST_)\n",
        "  \n",
        "  return MGST_layers_list\n",
        "\n",
        "def compute_MGST_Fermat(X, hom_dim, fermat_alpha) -> float:\n",
        "  distances_X = distance_matrix(X, X)\n",
        "  f_exact = Fermat(fermat_alpha, path_method='FW') \n",
        "  f_exact.fit(np.matrix(distances_X))\n",
        "  fermat_dist_exact = f_exact.get_distances()\n",
        "  MGST, _ = get_Betti_prob(fermat_dist_exact, eps=np.inf, alpha=1, maxdim=hom_dim)\n",
        "  lfts = round(MGST[hom_dim], 3)\n",
        "  return lfts"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f70p9nNjQh-7"
      },
      "source": [
        "def power_law(x, a, b):\n",
        "    return a*np.power(x, b)\n",
        "\n",
        "def PHdim(X, hom_dim, n, alpha=1):\n",
        "  n = 500\n",
        "  n_array = []\n",
        "  MGST_array = []\n",
        "  while X.shape[0] > n:\n",
        "    MGST, _ = get_Betti_prob(X[:n,:], np.inf, alpha, hom_dim)\n",
        "    MGST_array.append(MGST[hom_dim])\n",
        "\n",
        "    #MGST = compute_MGST_Fermat(X[:n,:], 0, 1)\n",
        "    #MGST_array.append(MGST)\n",
        "    n_array.append(n)\n",
        "    n += 450\n",
        "\n",
        "  x = np.array(n_array).reshape((-1, 1))\n",
        "  y = np.array(MGST_array)\n",
        "  model = LinearRegression().fit(np.log(x), np.log(y))\n",
        "  pars, pcov = curve_fit(power_law,  np.array(n_array),y)\n",
        "  #y = b0+b1*x\n",
        "  b1 = model.coef_[0]\n",
        "  b0 = model.intercept_\n",
        "  r_sq = model.score(x, y)\n",
        "  betta = math.log((sum(MGST_array)/len(MGST_array)))/math.log(n_array[-1])\n",
        "  #d = alpha/(1-betta) #(не работает)\n",
        "  #d = -1/(b1-1)\n",
        "  #d = -1/(pars[1]-1)\n",
        "  d = 1/(1-b1)\n",
        "  return round(d,2)\n",
        "#log(MGST) = a*log(n) + b + eps, α = (m − γ)/m"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdSn3FQ-QjS8"
      },
      "source": [
        "def PHDim_layers(model, data, layers, hom_dim, alpha):\n",
        "  class_ = 1\n",
        "  examples = 500\n",
        "  PHDim_layers_list = []\n",
        "  #layers_check = layers\n",
        "  SVDDim_layers_list = []\n",
        "  for lr in layers:\n",
        "    X_emb, layer_name = features_to_X(data, model, index_layer=lr) \n",
        "    #print(layer_name, X_emb.shape)\n",
        "    #X_emb = min_max_scaler.fit_transform(X_emb)\n",
        "    \n",
        "    X_emb_class = []\n",
        "    for e, i in enumerate(y_train[:examples]):\n",
        "      if i == class_: X_emb_class.append(X_emb[e])\n",
        "    X_emb_class = np.array(X_emb_class)\n",
        "\n",
        "    X_emb_class = np.array(X_emb)\n",
        "    PHdim_ = PHdim(X_emb_class, hom_dim = hom_dim, n = X_emb_class.shape[0], alpha=alpha)\n",
        "  \n",
        "    #print(f'{lr}) {PHdim_}')\n",
        "    PHDim_layers_list.append(PHdim_)\n",
        "  return PHDim_layers_list\n",
        "  \n",
        "def unistscount(layer_list: list) -> list:\n",
        "  return [round((e+1)/len(layer_list),2) for e,i in enumerate(layer_list)]\n",
        "\n",
        "def cocycles():\n",
        "  ripser(x_train[:1000].reshape((1000, 32*32*3)), maxdim=1, thresh=np.inf, do_cocycles=True)['cocycles'] "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsxQb-sGQljc"
      },
      "source": [
        "from math import sqrt\n",
        "def estimate_ID(X, fraction=0.9):            \n",
        "    # sort distance matrix\n",
        "    Y = np.sort(X,axis=1,kind='quicksort')\n",
        "    # clean data\n",
        "    k1 = Y[:,1]\n",
        "    k2 = Y[:,2]\n",
        "\n",
        "    zeros = np.where(k1 == 0)[0]\n",
        "    degeneracies = np.where(k1 == k2)[0]\n",
        "    good = np.setdiff1d(np.arange(Y.shape[0]), np.array(zeros) )\n",
        "    good = np.setdiff1d(good,np.array(degeneracies))\n",
        "\n",
        "    k1 = k1[good]\n",
        "    k2 = k2[good]    \n",
        "    \n",
        "    # n.of points to consider for the linear regression\n",
        "    npoints = int(np.floor(good.shape[0]*fraction))\n",
        "\n",
        "    # define mu and Femp\n",
        "    N = good.shape[0]\n",
        "    mu = np.sort(np.divide(k2, k1), axis=None,kind='quicksort')\n",
        "    Femp = (np.arange(1,N+1,dtype=np.float64) )/N\n",
        "    \n",
        "    # take logs (leave out the last element because 1-Femp is zero there)\n",
        "    x = np.log(mu[:-2])\n",
        "    y = -np.log(1 - Femp[:-2])\n",
        "\n",
        "    # regression\n",
        "    regr = linear_model.LinearRegression(fit_intercept=False)\n",
        "    regr.fit(x[0:npoints,np.newaxis],y[0:npoints,np.newaxis]) \n",
        "    r,pval = pearsonr(x[0:npoints], y[0:npoints])  \n",
        "    return x,y,regr.coef_[0][0],r,pval\n",
        "\n",
        "def estimate_ID_layers(model,data,layers_list,):\n",
        "    list_ID = []\n",
        "    for lr in layers_list:\n",
        "      X_emb, layer_name = features_to_X(data, model, index_layer=lr) \n",
        "      distances_X = distance_matrix(X_emb, X_emb)\n",
        "      ID = estimate_ID(distances_X, fraction=1.0)\n",
        "      list_ID.append(round(ID[2], 2))\n",
        "    return list_ID"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAtEOh_ERdTF"
      },
      "source": [
        "# Эксперименты"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyoxdN0AQsV0"
      },
      "source": [
        "# ИЗМЕНЕНИЕ PHdim ПО СЛОЯМ У МОДЕЛИ С РАЗНОЙ ШИРИНОЙ СЛОЁВ\n",
        "%%capture\n",
        "examples = 2000\n",
        "PHdim_Resnet_6_96 = [22] + PHDim_layers(Resnet_6_96, x_train[:examples], [14, 27, 49, 71, 93, 115, -2, -1], 0, alpha=1)\n",
        "PHdim_Resnet_6_64 = [22] + PHDim_layers(Resnet_6_64, x_train[:examples], [14, 27, 49, 71, 93, 115, -2, -1], 0, alpha=1)\n",
        "PHdim_Resnet_6_32 = [22] + PHDim_layers(Resnet_6_32, x_train[:examples], [14, 27, 49, 71, 93, 115, -2, -1], 0, alpha=1)\n",
        "PHdim_Resnet_6_20 = [22] + PHDim_layers(Resnet_6_20, x_train[:examples], [14, 27, 49, 71, 93, 115, -2, -1], 0, alpha=1)\n",
        "PHdim_Resnet_6_256 = [22] + PHDim_layers(Resnet_6_256, x_train[:examples], [14, 27, 49, 71, 93, 115, -2, -1], 0, alpha=1)\n",
        "PHdim_Resnet_6_128 = [22] + PHDim_layers(Resnet_6, x_train[:examples], [14, 27, 49, 71, 93, 115, -2, -1], 0, alpha=1)\n",
        "PHdim_Resnet_6_352 = [22] + PHDim_layers(Resnet_6_352, x_train[:examples], [14, 27, 49, 71, 93, 115, -2, -1], 0, alpha=1)\n",
        "PHdim_Resnet_6_412 = [22] + PHDim_layers(Resnet_6_412, x_train[:examples], [14, 27, 49, 71, 93, 115, -2, -1], 0, alpha=1)\n",
        "PHdim_Resnet_6_512 = [22] + PHDim_layers(Resnet_6_512, x_train[:examples], [14, 27, 49, 71, 93, 115, -2, -1], 0, alpha=1)\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECKItNa2ejmY"
      },
      "source": [
        "PHdim(X_emb_class, hom_dim = hom_dim, n = X_emb_class.shape[0], alpha=alpha)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1Z5qMKmXSx_",
        "outputId": "12193982-d699-4775-c5fa-065fa9604c0b"
      },
      "source": [
        "data_cifar10 = x_train[:examples].reshape((examples, 32*32*3))\n",
        "PHdim_cifar10 = PHdim(data_cifar10, hom_dim = 0, n = data_cifar10.shape[0], alpha=1)\n",
        "#distances_X = distance_matrix(data_cifar10, data_cifar10)\n",
        "#ID = estimate_ID(distances_X, fraction=1.0)\n",
        "print(round(PHdim_cifar10, 2))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6RcFGgJVDC-"
      },
      "source": [
        "%%capture\n",
        "layers_check = [14, 27, 49, 71, 93, 115, -2, -1]\n",
        "PHdim_cifar10 = [22]\n",
        "examples = 2000\n",
        "PHdim_Resnet_diff_width = []\n",
        "for model in Resnet_diff_width:\n",
        "  #PHdim_Resnet_diff_width.append(PHdim_cifar10 + PHDim_layers(model, x_train[:examples], layers_check, 0, alpha=1))\n",
        "  PHdim_Resnet_diff_width.append(MGST_layers(model, examples, layers_check, 0, 1, n_class=2, mode = 'local'))"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9nqE5W5ZstO"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "diff_width_model_dim = PHdim_Resnet_diff_width\n",
        "for ID_Resnet, name in zip(diff_width_model_dim, Resnet_diff_width_names):\n",
        "  plt.plot(range(len(ID_Resnet)), ID_Resnet, 'o-',  linewidth=0.7, markersize=5, label=name)\n",
        "ax.grid(which='major', color='#CCCCCC', linestyle='--', alpha=0.35)\n",
        "plt.legend()\n",
        "plt.title('ID_across_different width model')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUquwN9rbo56"
      },
      "source": [
        "n = 3\n",
        "ID_layer = [id_l[n] for id_l in ID_Resnet_diff_width ]\n",
        "ID_max = [max(id_l[1:]) for id_l in PHdim_Resnet_diff_width]\n",
        "depths = [20,32,64,96,128,256,352,412,512]\n",
        "fig, ax = plt.subplots(figsize=(18, 8))\n",
        "plt.plot(depths, ID_max, 'o-',  linewidth=0.7, markersize=5, label='depth vs id' )\n",
        "ax.grid(which='major', color='#CCCCCC', linestyle='--', alpha=0.35)\n",
        "ax.set_xticklabels(Resnet_diff_width_names,rotation=40)\n",
        "plt.xticks([20,32,64,96,128,256,352,412,512])\n",
        "plt.title('Фиксированная длина, разная ширина. Изменение максимальной внутренней фрактальной размерости в зависимости от ширины')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bp14a-nsQsdH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkbpeLs2RaJz"
      },
      "source": [
        "# Загрузка моделей"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkegigmxQsft"
      },
      "source": [
        "Resnet_6_128 = keras.models.load_model('/content/drive/MyDrive/ML_materials/resnet/Resnet_6_128_0.87.h5') \n",
        "Resnet_6_96 = keras.models.load_model('/content/drive/MyDrive/ML_materials/Resnet_type_96/Resnet96_0.858.h5') \n",
        "Resnet_6_64 = keras.models.load_model('/content/drive/MyDrive/ML_materials/Resnet_type_96/Resnet_6_64_0.858.h5') \n",
        "Resnet_6_32 = keras.models.load_model('/content/drive/MyDrive/ML_materials/Resnet_type_96/Resnet_6_32_0.77.h5') \n",
        "Resnet_6_20 = keras.models.load_model('/content/drive/MyDrive/ML_materials/Resnet_type_96/Resnet_6_20_0.71.h5') \n",
        "Resnet_6_256 = keras.models.load_model('/content/drive/MyDrive/ML_materials/Resnet_type_96/Resnet_6_256_0.88.h5') \n",
        "Resnet_6_352 = keras.models.load_model('/content/drive/MyDrive/ML_materials/Resnet_type_96/Resnet_6_352_0.88.h5') \n",
        "Resnet_6_412 = keras.models.load_model('/content/drive/MyDrive/ML_materials/Resnet_type_96/Resnet_6_412_0.88.h5') \n",
        "Resnet_6_512 = keras.models.load_model('/content/drive/MyDrive/ML_materials/Resnet_type_96/Resnet_6_512_0.89.h5') "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67mFO0TlQ2xN"
      },
      "source": [
        "Resnet_diff_width = [Resnet_6_20,Resnet_6_32,Resnet_6_64,Resnet_6_96,Resnet_6_128,Resnet_6_256,Resnet_6_352,Resnet_6_412,Resnet_6_512]\n",
        "Resnet_diff_width_names = ['Resnet_6_20 71%','Resnet_6_32 77%','Resnet_6_64 85%','Resnet_6_96 86%', 'Resnet_6_128 87%', 'Resnet_6_256 88%',\n",
        "                           'Resnet_6_352 88%','Resnet_6_412 88%','Resnet_6_512 89%']"
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}